{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "json_dataset_augmented.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwxIcBsXuFW2"
      },
      "source": [
        "##Aumento de imagenes y generación de archivos json\n",
        "\n",
        "#####Input: imagenes y archivos .xml o .json desde Github\n",
        "#####Output: imagenes aumentadas y json de las mismas a Github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYW_Tdi7V4Sf"
      },
      "source": [
        "####Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRoJbJldUGuj"
      },
      "source": [
        "generate_images_count =  3#@param {type:\"integer\"}\n",
        "\n",
        "# mostrar imagenes originales y sus transformaciones, para debug\n",
        "show_generated_images = True #@param {type:\"boolean\"}\n",
        "images_to_show =  15#@param {type:\"integer\"}\n",
        "\n",
        "images_repo_url = 'https://github.com/cololaborde/etiquetado' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(images_repo_url)))\n",
        "path_annotations = repo_dir_path+'/annotations' \n",
        "path_images_train = repo_dir_path+'/Guille-Tomas/original/train'\n",
        "path_images_test = repo_dir_path+'/Guille-Tomas/original/test' \n",
        "\n",
        "github_pass = 'colo41212209' #@param {type:\"string\"}\n",
        "github_mail = 'cololaborde@gmail.com' #@param {type:\"string\"}\n",
        "github_user = 'cololaborde' #@param {type:\"string\"}\n",
        "repo_name = 'etiquetado' #@param {type:\"string\"}\n",
        "labeled_with = 'labelme (poligonos)' #@param [\"labelimg\", \"labelme (poligonos)\"]\n",
        "\n",
        "repo = 'https://'+github_user + ':' +github_pass+'@github.com/'+github_user+'/'+repo_name+'.git'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeJEEzxTWCl-"
      },
      "source": [
        "####Clonamos repo con imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxIEIeWnaYYa",
        "outputId": "3d7ff4ee-2ad3-4970-91b4-23ccac1d9faf"
      },
      "source": [
        "%cd /content\n",
        "!git clone {repo}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'etiquetado'...\n",
            "remote: Enumerating objects: 830, done.\u001b[K\n",
            "remote: Counting objects: 100% (830/830), done.\u001b[K\n",
            "remote: Compressing objects: 100% (493/493), done.\u001b[K\n",
            "remote: Total 830 (delta 409), reused 758 (delta 337), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (830/830), 28.03 MiB | 27.10 MiB/s, done.\n",
            "Resolving deltas: 100% (409/409), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5CpnhmN_oP",
        "outputId": "29657848-9ea9-473b-e6af-65189ace46a8"
      },
      "source": [
        "print(repo_dir_path)\n",
        "print(path_annotations)\n",
        "print(path_images_test)\n",
        "print(path_images_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/etiquetado\n",
            "/content/etiquetado/annotations\n",
            "/content/etiquetado/Guille-Tomas/original/test\n",
            "/content/etiquetado/Guille-Tomas/original/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtU39QneWGd9"
      },
      "source": [
        "####Instalamos libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKRF6s9Xer-N",
        "outputId": "1aeaf027-e755-4bd0-8d37-700bce32c176"
      },
      "source": [
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%tensorflow_version 1.x\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n",
        "from imgaug import augmenters as iaa \n",
        "import imageio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "\n",
        "import json\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "TensorFlow 1.x selected.\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOkJ77C4kWwW"
      },
      "source": [
        "####Funciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma8UHgfKHUbQ"
      },
      "source": [
        "# Function that will extract column data for our CSV file as pandas DataFrame\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "   \n",
        "# apply the function to convert all XML files in images/ folder into labels.csv\n",
        "if os.path.exists(path_annotations):\n",
        "  shutil.rmtree(path_annotations)\n",
        "\n",
        "os.mkdir(path_annotations) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFUz3fu6TF9N"
      },
      "source": [
        "# Function that will extract column data for our CSV file as pandas DataFrame\n",
        "def json_to_csv(path):\n",
        "    json_list = []\n",
        "    for json_file in glob.glob(path + '/*.json'):\n",
        "        json_read = open(json_file)\n",
        "        json_loaded = json.load(json_read)\n",
        "        #save width and height\n",
        "        height = json_loaded[\"imageHeight\"]\n",
        "        width = json_loaded[\"imageWidth\"]\n",
        "        filename = json_loaded[\"imagePath\"]\n",
        "        #iterate labels and points\n",
        "        for elements in json_loaded[\"shapes\"]:\n",
        "            label = elements[\"label\"]\n",
        "            points = elements[\"points\"]\n",
        "            xmin = round(points[0][0]) + 1\n",
        "            xmax = round(points[2][0]) + 1\n",
        "            ymin = round(points[1][1]) + 1\n",
        "            try:\n",
        "              ymax = round(points[3][1]) + 1\n",
        "            except:\n",
        "              print('Este archivo requiere intervención manual, debido a que contiene poligonos con menos de 4 puntos: ' + str(json_file))\n",
        "            value = (filename, width, height, label, xmin, ymin, xmax, ymax)\n",
        "            json_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    json_df = pd.DataFrame(json_list, columns=column_name)\n",
        "    return json_df\n",
        "   \n",
        "# apply the function to convert all XML files in images/ folder into labels.csv\n",
        "if os.path.exists(path_annotations):\n",
        "  shutil.rmtree(path_annotations)\n",
        "\n",
        "os.mkdir(path_annotations) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwHIm9hhc1r7"
      },
      "source": [
        "# function to convert BoundingBoxesOnImage object into DataFrame\n",
        "def bbs_obj_to_df(bbs_object):\n",
        "#     convert BoundingBoxesOnImage object into array\n",
        "    bbs_array = bbs_object.to_xyxy_array()\n",
        "#     convert array into a DataFrame ['xmin', 'ymin', 'xmax', 'ymax'] columns\n",
        "    df_bbs = pd.DataFrame(bbs_array, columns=['xmin', 'ymin', 'xmax', 'ymax'])\n",
        "    return df_bbs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMioOaJ8Hf-A"
      },
      "source": [
        "def image_aug(df, images_path, aug_images_path, image_prefix, augmentor):\n",
        "    # create data frame which we're going to populate with augmented image info\n",
        "    aug_bbs_xy = pd.DataFrame(columns=\n",
        "                              ['filename','width','height','class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "                             )\n",
        "    grouped = df.groupby('filename')\n",
        "    \n",
        "    for filename in df['filename'].unique():\n",
        "    #   get separate data frame grouped by file name\n",
        "        group_df = grouped.get_group(filename)\n",
        "        group_df = group_df.reset_index()\n",
        "        group_df = group_df.drop(['index'], axis=1)   \n",
        "    #   read the image\n",
        "        image = imageio.imread(images_path+filename)\n",
        "    #   get bounding boxes coordinates and write into array        \n",
        "        bb_array = group_df.drop(['filename', 'width', 'height', 'class'], axis=1).values\n",
        "    #   pass the array of bounding boxes coordinates to the imgaug library\n",
        "        bbs = BoundingBoxesOnImage.from_xyxy_array(bb_array, shape=image.shape)\n",
        "    #   apply augmentation on image and on the bounding boxes\n",
        "        image_aug, bbs_aug = augmentor(image=image, bounding_boxes=bbs)\n",
        "    #   disregard bounding boxes which have fallen out of image pane    \n",
        "        bbs_aug = bbs_aug.remove_out_of_image()\n",
        "    #   clip bounding boxes which are partially outside of image pane\n",
        "        bbs_aug = bbs_aug.clip_out_of_image()\n",
        "        \n",
        "    #   don't perform any actions with the image if there are no bounding boxes left in it    \n",
        "        if re.findall('Image...', str(bbs_aug)) == ['Image([]']:\n",
        "            pass\n",
        "        \n",
        "    #   otherwise continue\n",
        "        else:\n",
        "        #   write augmented image to a file\n",
        "            imageio.imwrite(aug_images_path+image_prefix+filename, image_aug)  \n",
        "        #   create a data frame with augmented values of image width and height\n",
        "            info_df = group_df.drop(['xmin', 'ymin', 'xmax', 'ymax'], axis=1)    \n",
        "            for index, _ in info_df.iterrows():\n",
        "                info_df.at[index, 'width'] = image_aug.shape[1]\n",
        "                info_df.at[index, 'height'] = image_aug.shape[0]\n",
        "        #   rename filenames by adding the predifined prefix\n",
        "            info_df['filename'] = info_df['filename'].apply(lambda x: image_prefix+x)\n",
        "        #   create a data frame with augmented bounding boxes coordinates using the function we created earlier\n",
        "            bbs_df = bbs_obj_to_df(bbs_aug)\n",
        "        #   concat all new augmented info into new data frame\n",
        "            aug_df = pd.concat([info_df, bbs_df], axis=1)\n",
        "        #   append rows to aug_bbs_xy data frame\n",
        "            aug_bbs_xy = pd.concat([aug_bbs_xy, aug_df])            \n",
        "    \n",
        "    # return dataframe with updated images and bounding boxes annotations \n",
        "    aug_bbs_xy = aug_bbs_xy.reset_index()\n",
        "    aug_bbs_xy = aug_bbs_xy.drop(['index'], axis=1)\n",
        "    return aug_bbs_xy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2ATZKCGFldV",
        "outputId": "0997726b-5e8e-41cc-b641-f703cb282144"
      },
      "source": [
        "if(labeled_with == 'labelme (poligonos)'):\n",
        "  train_labels_df = json_to_csv(path_images_train)\n",
        "  train_labels_df.to_csv((path_annotations+'/temp_train_labels.csv'), index=None)\n",
        "\n",
        "  test_labels_df = json_to_csv(path_images_test)\n",
        "  test_labels_df.to_csv((path_annotations+'/temp_test_labels.csv'), index=None)\n",
        "else:\n",
        "  train_labels_df = xml_to_csv(path_images_train)\n",
        "  train_labels_df.to_csv((path_annotations+'/temp_train_labels.csv'), index=None)\n",
        "\n",
        "  test_labels_df = xml_to_csv(path_images_test)\n",
        "  test_labels_df.to_csv((path_annotations+'/temp_test_labels.csv'), index=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Este archivo requiere intervención manual, debido a que contiene poligonos con menos de 4 puntos: /content/etiquetado/Guille-Tomas/original/train/EDF 07-EST-06.json\n",
            "Este archivo requiere intervención manual, debido a que contiene poligonos con menos de 4 puntos: /content/etiquetado/Guille-Tomas/original/train/EDF 07-EST-06.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpvV_Jk-DTCM"
      },
      "source": [
        "las transformaciones son las de la libreria albumnations, que es un wrapper de imgaug .. las posibles opciones son las mencionadas en https://albumentations.readthedocs.io/en/latest/api/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDULYmHic86-"
      },
      "source": [
        "aug = iaa.SomeOf(2, [    \n",
        "    iaa.Affine(scale=(0.5, 1.5)),\n",
        "    #iaa.Affine(rotate=(-60, 60)),\n",
        "    iaa.Affine(translate_percent={\"x\":(-0.3, 0.3),\"y\":(-0.3, 0.3)}),\n",
        "    iaa.Fliplr(1),\n",
        "    iaa.GaussianBlur(sigma=(1.0, 3.0)),\n",
        "    iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.05*255))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab2pk5h5dCUW"
      },
      "source": [
        "if os.path.exists(path_images_train+'/aug_images'):\n",
        "  shutil.rmtree(path_images_train+'/aug_images')\n",
        "os.mkdir(path_images_train+'/aug_images') \n",
        "\n",
        "if os.path.exists(path_images_test+'/aug_images'):\n",
        "  shutil.rmtree(path_images_test+'/aug_images')\n",
        "os.mkdir(path_images_test+'/aug_images') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd_ftSrOHkZj"
      },
      "source": [
        "####Aumentamos imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uji4U6PqdFWo"
      },
      "source": [
        "# initialize empty DataFrame\n",
        "augmented_images_train_df = pd.DataFrame(columns=['filename','width','height','class','xmin','ymin','xmax','ymax'])\n",
        "# apply augmentation function 5 times to the same set of images\n",
        "for i in range(generate_images_count):\n",
        "    aug_df = image_aug(train_labels_df, path_images_train+'/', path_images_train+'/aug_images/', 'aug'+str(i)+'_', aug)\n",
        "    augmented_images_train_df = pd.concat([augmented_images_train_df, aug_df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qds5PjRrQ-r"
      },
      "source": [
        "###Mostramos imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO9wBpVteqPh"
      },
      "source": [
        "if show_generated_images:\n",
        "  %matplotlib inline\n",
        "  import matplotlib as mpl\n",
        "  import matplotlib.pyplot as plt\n",
        "  import PIL.ImageDraw as ImageDraw\n",
        "  IMAGE_SIZE = (16, 16)\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  for filename in train_labels_df['filename'].unique():\n",
        "    \n",
        "    if i == images_to_show:\n",
        "      break;\n",
        "\n",
        "    asd = augmented_images_train_df[augmented_images_train_df[\"filename\"].str.contains(filename)]\n",
        "    \n",
        "    for filename1 in asd['filename'].unique():\n",
        "      grouped = asd.groupby('filename')\n",
        "      group_df = grouped.get_group(filename1)\n",
        "    \n",
        "      plt.figure(figsize=IMAGE_SIZE)\n",
        "      image = imageio.imread(path_images_train+'/aug_images/'+filename1)\n",
        "      plt.imshow(image)\n",
        "\n",
        "      for index, row in group_df.iterrows():\n",
        "          coord = [[row['xmin'], row['ymax']], [row['xmax'], row['ymax']], [row['xmax'], row['ymin']], [row['xmin'], row['ymin']]]\n",
        "         \n",
        "          coord.append(coord[0]) #repeat the first point to create a 'closed loop'\n",
        "          coord.append(coord[1])\n",
        "          coord.append(coord[2])\n",
        "          coord.append(coord[3])\n",
        "          xs, ys = zip(*coord) #create lists of x and y values\n",
        "          plt.plot(xs,ys, linewidth=2) \n",
        "    \n",
        "    i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO7_9ORPrWrW"
      },
      "source": [
        "###Aumento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdXRbQCJZ-mb"
      },
      "source": [
        "# initialize empty DataFrame\n",
        "augmented_images_test_df = pd.DataFrame(columns=['filename','width','height','class','xmin','ymin','xmax','ymax'])\n",
        "# apply augmentation function 5 times to the same set of images\n",
        "for i in range(int(generate_images_count)):\n",
        "    aug_df = image_aug(test_labels_df, path_images_test+'/', path_images_test+'/aug_images/', 'aug'+str(i)+'_', aug)\n",
        "    augmented_images_test_df = pd.concat([augmented_images_test_df, aug_df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF48bKZPdIcN"
      },
      "source": [
        "all_labels_train_df = pd.concat([train_labels_df, augmented_images_train_df])\n",
        "all_labels_train_df.to_csv(path_annotations+'/train_labels.csv', index=False)\n",
        "\n",
        "\n",
        "all_labels_test_df = pd.concat([test_labels_df, augmented_images_test_df])\n",
        "all_labels_test_df.to_csv(path_annotations+'/test_labels.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ftz_tVKdJzg"
      },
      "source": [
        "''' for file in os.listdir(path_images_train+'/aug_images/'):\n",
        "    shutil.copy(path_images_train+'/aug_images/'+file, path_images_train+'/'+file)\n",
        "\n",
        "for file in os.listdir(path_images_test+'/aug_images/'):\n",
        "    shutil.copy(path_images_test+'/aug_images/'+file, path_images_test+'/'+file) '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5pVpxzqk1vz"
      },
      "source": [
        "####Eliminamos recursos innecesarios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVVU8uoLdap8"
      },
      "source": [
        "# clear resources\n",
        "!rm '{path_annotations}/temp_train_labels.csv'\n",
        "!rm '{path_annotations}/temp_test_labels.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWBaOcD0FW6c"
      },
      "source": [
        "###Generamos los .json para las imagenes aumentadas (labelme) o para todas las imagenes (labelimg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIyGKY0n2Rsv"
      },
      "source": [
        "def csv_to_json(csv_to_open, path_to_save) :\n",
        "\n",
        "    files = {}\n",
        "    all_data = {}   \n",
        "    data = []\n",
        "\n",
        "    with open(csv_to_open, mode='r') as csv_file: #me quedo con los nombres de las imagenes, sin repetidos\n",
        "      csv_reader = csv.DictReader(csv_file)\n",
        "      for row in csv_reader:\n",
        "        if(labeled_with == 'labelme'): #si es etiquetado con labelme\n",
        "          if('aug' in row['filename']): #genero un json por cada imagen aumentada nueva\n",
        "            files[row['filename']] = ''\n",
        "        else:                           #si fue etiquetado con labelimg,\n",
        "          files[row['filename']] = ''   #genero un json para cada imagen\n",
        "\n",
        "    for i in files:   #por cada correspondiente imagen\n",
        "      csv_file = open(csv_to_open, mode='r')  \n",
        "      csv_reader = csv.DictReader(csv_file)\n",
        "      for row in csv_reader:    #leo el csv con toda la informacion de todas las imagenes\n",
        "          if(str(i) == str(row['filename'])): #si corresponde\n",
        "              #guardo la informacion para generar el json\n",
        "              data.append([row['class'], row['xmin'], row['ymin'], row['xmax'], row['ymax'], row['width'], row['height']]) \n",
        "    \n",
        "      all_data[i] = data\n",
        "      data = []\n",
        "    \n",
        "    write_json = {}\n",
        "\n",
        "\n",
        "    for image in all_data:\n",
        "        \n",
        "        store_json = open(path_to_save + '/' + image[:-4] + '.json', 'w+')\n",
        "\n",
        "        write_json[\"verion\"] = \"3.16.7\"\n",
        "        write_json[\"flags\"] = {}\n",
        "        write_json[\"shapes\"] = []\n",
        "\n",
        "\n",
        "        for elem in all_data[image]: # por cada elemento detectado, obtengo xmin ymin xmax ymax\n",
        "            if (elem[1] != '' and elem[2] != '' and elem[3] != '' and elem[4] != ''):\n",
        "              p1 = (float(elem[1]))\n",
        "              p2 = (float(elem[2]))\n",
        "              p3 = (float(elem[3]))\n",
        "              p4 = (float(elem[4]))\n",
        "              write_json[\"shapes\"].append(({\"label\": elem[0], \"line_color\": None, \"fill_color\": None, \"points\": [  [ p1, p2 ], [ p3, p2 ], [ p3, p4 ], [ p1, p4 ] ] , \"shape_type\":\"polygon\", \"flags\":{} }))\n",
        "\n",
        "        write_json[\"line_color\"] = [0, 255, 0, 128]\n",
        "        write_json[\"fillColor\"] = [255, 0, 0, 128]\n",
        "        write_json[\"imagePath\"] = image\n",
        "        write_json[\"imageData\"] = \"\"\n",
        "        write_json[\"imageHeight\"] = 1280\n",
        "        write_json[\"imageWidth\"] = 1600\n",
        "\n",
        "        #escribo el json\n",
        "        store_json.seek(0)\n",
        "        json.dump(write_json,store_json,indent=4)\n",
        "        store_json.truncate()\n",
        "\n",
        "    print('Conversiones finalizadas...')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv7Ee15Ss1Sn",
        "outputId": "56b76cf2-2f6e-433d-88dd-a63c6a223a7f"
      },
      "source": [
        "csv_to_open = '/content/' + repo_name + '/annotations/test_labels.csv'\n",
        "path_to_save = path_images_test +'/aug_images/'\n",
        "csv_to_json(csv_to_open, path_to_save)\n",
        "csv_to_open = '/content/'+ repo_name + '/annotations/train_labels.csv'\n",
        "path_to_save = path_images_train +'/aug_images/'\n",
        "csv_to_json(csv_to_open, path_to_save)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conversiones finalizadas...\n",
            "Conversiones finalizadas...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhMdBrWhGdL0"
      },
      "source": [
        "###Subimos los archivos a github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q92tAIYGWwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e347e05-eaa1-49f3-e141-a11ed3a14328"
      },
      "source": [
        "%cd {repo_dir_path}\n",
        "!git remote rm origin\n",
        "!git init\n",
        "!git remote add origin {repo}\n",
        "!git config --global user.email {github_mail}\n",
        "!git config --global user.name {github_user}\n",
        "\n",
        "!git add .\n",
        "''' \n",
        "%cd {path_annotations}\n",
        "#!git add test.record\n",
        "#!git add train.record\n",
        "!git add label_map.pbtxt\n",
        "!git commit -m 'tfrecords actualizados'\n",
        "\n",
        "%cd {path_images_train+'/aug_images'}\n",
        "!git add .\n",
        "%cd {path_images_test+'/aug_images'}\n",
        "!git add . '''\n",
        "!git commit -m \"aumentadas\"\n",
        "\n",
        "\n",
        "!git push -u origin master  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/etiquetado\n",
            "Reinitialized existing Git repository in /content/etiquetado/.git/\n",
            "[master 8f678ae] aumentadas\n",
            " 163 files changed, 90101 insertions(+), 2977 deletions(-)\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/EDF 03 - EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/EDF 07-EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/EDF 07-EST-03.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/EDF 07-EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/EDF 07-EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/EDF 08 - EST-02.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 03 - EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 03 - EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 07-EST-01.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 07-EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 07-EST-03.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 07-EST-03.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 07-EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 07-EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 07-EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 07-EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 08 - EST-02.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug0_EDF 08 - EST-02.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 03 - EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 03 - EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 07-EST-01.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 07-EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 07-EST-03.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 07-EST-03.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 07-EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 07-EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 07-EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 07-EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 08 - EST-02.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug1_EDF 08 - EST-02.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 03 - EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 03 - EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 07-EST-01.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 07-EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 07-EST-03.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 07-EST-03.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 07-EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 07-EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 07-EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 07-EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 08 - EST-02.jpg\n",
            " create mode 100644 Guille-Tomas/original/test/aug_images/aug2_EDF 08 - EST-02.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/06 EDF EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/06 EDF EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/06 EDF EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/06 EDF EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/06 EDF EST-07.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/06 EDF EST-08.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/E014-EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/E014-EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/E014-EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/EDF 03 - EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/EDF 03 - EST-07.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/EDF 03 - EST-08.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/EDF 07-EST-02.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/EDF 07-EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/EDF 08 - EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/EDF 08 - EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/EDF 08 - EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-01.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-07.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-07.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-08.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_06 EDF EST-08.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_E014-EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_E014-EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_E014-EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_E014-EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_E014-EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_E014-EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 03 - EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 03 - EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 03 - EST-07.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 03 - EST-07.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 03 - EST-08.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 03 - EST-08.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 07-EST-02.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 07-EST-02.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 07-EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 07-EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 08 - EST-01.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 08 - EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 08 - EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 08 - EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 08 - EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug0_EDF 08 - EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-01.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-07.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-07.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-08.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_06 EDF EST-08.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_E014-EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_E014-EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_E014-EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_E014-EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_E014-EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_E014-EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 03 - EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 03 - EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 03 - EST-07.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 03 - EST-07.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 03 - EST-08.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 03 - EST-08.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 07-EST-02.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 07-EST-02.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 07-EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 07-EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 08 - EST-01.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 08 - EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 08 - EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 08 - EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 08 - EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug1_EDF 08 - EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-01.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-07.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-07.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-08.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_06 EDF EST-08.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_E014-EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_E014-EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_E014-EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_E014-EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_E014-EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_E014-EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 03 - EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 03 - EST-05.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 03 - EST-07.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 03 - EST-07.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 03 - EST-08.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 03 - EST-08.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 07-EST-02.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 07-EST-02.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 07-EST-06.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 07-EST-06.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 08 - EST-01.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 08 - EST-01.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 08 - EST-04.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 08 - EST-04.json\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 08 - EST-05.jpg\n",
            " create mode 100644 Guille-Tomas/original/train/aug_images/aug2_EDF 08 - EST-05.json\n",
            " rewrite annotations/train_labels.csv (76%)\n",
            "Counting objects: 172, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (162/162), done.\n",
            "Writing objects: 100% (172/172), 10.17 MiB | 10.02 MiB/s, done.\n",
            "Total 172 (delta 102), reused 19 (delta 10)\n",
            "remote: Resolving deltas: 100% (102/102), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/cololaborde/etiquetado.git\n",
            "   b178983..8f678ae  master -> master\n",
            "Branch 'master' set up to track remote branch 'master' from 'origin'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUcKc2H2HN_k"
      },
      "source": [
        "###Listo."
      ]
    }
  ]
}